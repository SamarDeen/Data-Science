{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from outputmethods import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, precision_recall_curve, auc, make_scorer, recall_score, precision_score,roc_auc_score\n",
    "\n",
    "#pmml wrapper\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-defined functions - a collection of codes that I use frequently during model build. \n",
    "#This code has been shared by collegues, friends, and stack overflow \n",
    "\n",
    "def CreateDecileAnalysis(d, numBins):\n",
    "    # deciles is a dataframe with the following columns:\n",
    "    # [PROB, PRED, TARG]\n",
    "    d = d.copy()\n",
    "    d['PROB_MIN'] = d['PROB']\n",
    "    d['PROB_MAX'] = d['PROB']\n",
    "    d.rename(columns={'PROB': 'PROB_AVG'}, inplace=True)\n",
    "    d['RECS'] = 1\n",
    "    d['BINS'] = pd.qcut(d['PROB_MIN'].rank(method = 'first'), numBins, labels=False, duplicates='drop')\n",
    "\n",
    "    d = d.groupby('BINS', as_index=False).agg(\n",
    "        {'PROB_MIN': np.min, 'PROB_AVG': np.mean, 'PROB_MAX': np.max,  'TARGET': np.sum, 'RECS': np.sum})\n",
    "    \n",
    "    d['PROB_MIN'] = d['PROB_MIN'].round(15)\n",
    "    d['PROB_AVG'] = d['PROB_AVG'].round(15)\n",
    "    d['PROB_MAX'] = d['PROB_MAX'].round(15)\n",
    "\n",
    "    d = d.reindex(columns=['BINS', 'PROB_AVG', \n",
    "                           'TARGET',\n",
    "                           'RECS', 'PROB_MIN', 'PROB_MAX'])\n",
    "    d = d.sort_values('BINS', ascending=False)\n",
    "    d['BINS'] = d['BINS'].astype(str)\n",
    "    # Output: Deciles\n",
    "    return d\n",
    "\n",
    "def CreateROCcurve(results):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(results['TARGET'], results['PROB'])\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.figure(2, figsize=(10, 10))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    Read the data into pandas dataframe\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path,encoding = 'iso-8859-1')\n",
    "    return data\n",
    "\n",
    "def get_headers(dataset): \n",
    "    return dataset.columns.values\n",
    "\n",
    "#grid search for hyperparameters\n",
    "def grid_search_hyperparameter():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 31, stop = 200, num = 55)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt','log2']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(15, 45, num = 20)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 3,5]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [ 10,20, 30, 40, 50,100,150]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "    return random_grid\n",
    "    \n",
    "para_grid = grid_search_hyperparameter()\n",
    "random_grid = grid_search_hyperparameter()\n",
    "\n",
    "def handle_null_values():\n",
    "    target = model_data['TARGET']\n",
    "    target = target.replace('$null$', 0)\n",
    "    features = model_data.drop('TARGET', axis = 1)\n",
    "    features = features.replace('$null$', -1)\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = 'C:/Users/SamarDeen/Desktop/Data/train.csv'\n",
    "INPUT_PATH_TEST = 'C:/Users/SamarDeen/Desktop/Data/test.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data(INPUT_PATH)\n",
    "test = read_data(INPUT_PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view all columns\n",
    "for c in (train.columns):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset features\n",
    "train_features = train[['A','B','C']]\n",
    "test_features = m2n_test[['A','B','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target  = train['TARGET']\n",
    "train_target.head()\n",
    "test_target  = test['TARGET']\n",
    "test_target.head()\n",
    "test_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "#get statistics\n",
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics for model selection\n",
    "scorers = {'recall_score': make_scorer(recall_score)}\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state = 42,criterion = 'gini')\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "refit_score = 'recall_score'\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = 1,scoring = scorers, refit = refit_score,return_train_score = True)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features_new, train_target_new)\n",
    "# Hyperparameters for the best performing random forest\n",
    "rf_random.best_params_\n",
    "rf_random.cv_results_\n",
    "rf_random.best_score_\n",
    "rf_random.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestClassifier(n_estimators = 90 , min_samples_split=2, min_samples_leaf = 2,\n",
    "                                   max_features = 0.13, max_depth= 12, bootstrap = True, \n",
    "                                   criterion = 'entropy', random_state = 42)\n",
    "regressor.fit(train_features, train_target)\n",
    "cutoff = 0.001628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for training set\n",
    "pro_t = regressor.predict_proba(train_features)\n",
    "proba_t = pd.DataFrame(pro_t, columns = ['0','1'])\n",
    "proba_t ['prediction'] = np.where(proba_t['1'] >= cutoff, 1, 0)\n",
    "conf_train = confusion_matrix(train_target, proba_t['prediction'])\n",
    "TN = conf_train[0,0]\n",
    "FP = conf_train[0,1]\n",
    "FN = conf_train[1,0]\n",
    "TP = conf_train[1,1]\n",
    "\n",
    "print(TN , FP , TP , FN)\n",
    "print('True Negative Rate: ', (TN/(TN+FP)).round(3))\n",
    "print('True Positive Rate: ', (TP/(TP+FN)).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset and choose columns\n",
    "mod_data = m2n_train[['TARGET']]\n",
    "mod_data.head()\n",
    "proba_t.rename(columns={'1': 'PROB'}, inplace=True)\n",
    "proba_t.rename(columns={'prediction': 'PRED'}, inplace=True)\n",
    "proba_t.head()\n",
    "d = pd.concat([proba_t, mod_data],axis=1)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateDecileAnalysis(d, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under Curve - ROC Curve\n",
    "lm_auc = roc_auc_score(d['TARGET'], d['PROB'])\n",
    "print('\\nAUC: ' + str(lm_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateROCcurve(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(train_features.columns)\n",
    "# Get numerical feature importance\n",
    "importances = list(regressor.feature_importances_)\n",
    "#List of tuples with variable and importance\n",
    "feature_importances = [(features, importance) for features,importance in zip(feature_list, importances)]\n",
    "#Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "#Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.predict(test_features)\n",
    "pro = regressor.predict_proba(test_features)\n",
    "proba = pd.DataFrame(pro, columns = ['0','1'])\n",
    "proba['prediction'] = np.where(proba['1'] >= cutoff, 1, 0)\n",
    "conf = confusion_matrix(test_target,proba['prediction']) \n",
    "TN = conf[0,0]\n",
    "FP = conf[0,1]\n",
    "FN = conf[1,0]\n",
    "TP = conf[1,1]\n",
    "print(TN , FP , TP , FN)\n",
    "print('True Negative Rate: ', (TN/(TN+FP)).round(3))\n",
    "print('True Positive Rate: ', (TP/(TP+FN)).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge predicted probability of test data with Target\n",
    "proba.rename(columns={'1': 'PROB'}, inplace=True)\n",
    "proba.rename(columns={'prediction': 'PRED'}, inplace=True)\n",
    "proba.head()\n",
    "test_data = m2n_test[['TARGET']]\n",
    "d_test = pd.concat([proba, test_data], axis=1)\n",
    "#d_test.head()\n",
    "CreateDecileAnalysis(d_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "d_test.to_csv('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PMMLPipeline([(\"classifier\", regressor)])\n",
    "pipeline.fit(train,target)\n",
    "sklearn2pmml(pipeline, \"Model.pmml\", with_repr = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
